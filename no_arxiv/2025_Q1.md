| Week       | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Paper-Link                                                                                                          | Tweet-Link                                              | Other-Links                                                                                                                                                                                                                                            |
|:-----------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 2025-03-30 | Tracing the Thoughts of LLMs  Anthropic researchers unveil new interpretability tools for peering inside LLMs, using Claude 3.5 Haiku as a testbed. Their two new papers show how to trace model internals like circuits, plans, and conceptual thinking in real time. Key findings:   ● Multilingual "language of thought"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | nan                                                                                                                 | https://x.com/AnthropicAI/status/1905303835892990278    | {"Blog": "https://www.anthropic.com/research/tracing-thoughts-language-model", "Paper 1": "https://transformer-circuits.pub/2025/attribution-graphs/methods.html", "Paper 2": "https://transformer-circuits.pub/2025/attribution-graphs/biology.html"} |
| 2025-03-30 | Qwen2.5-Omni  Qwen2.5-Omni is a single end-to-end multimodal model that can perceive and understand text, audio, image, and video, and generate both text and speech in real time. It introduces architectural and training innovations that push the boundaries of streaming, multi-signal intelligence. Highlights:   ● Thinker-Talker architecture                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | https://github.com/QwenLM/Qwen2.5-Omni/blob/main/assets/Qwen2.5_Omni.pdf                                            | https://x.com/Alibaba_Qwen/status/1904944923159445914   | nan                                                                                                                                                                                                                                                    |
| 2025-03-30 | Neural Alignment via Speech Embeddings  Google Research and collaborators reveal striking similarities between LLM embeddings and human brain activity during conversation. Key insights:   ● Embeddings match brain signals                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | https://www.nature.com/articles/s41562-025-02105-9                                                                  | https://x.com/omarsar0/status/1904947715458711706       | nan                                                                                                                                                                                                                                                    |
| 2025-03-30 | Investigating Affective Use and Emotional Well-being on ChatGPT  Researchers from OpenAI & MIT Media Lab explore how emotionally engaging interactions with ChatGPT (especially in Voice Mode) may impact user well-being. Using platform-wide data and a randomized controlled trial (RCT), they uncover nuanced effects of chatbot usage on loneliness, dependence, and socialization.   ● Two complementary studies                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | https://cdn.openai.com/papers/15987609-5f71-433c-9972-e91131f399a1/openai-affective-use-study.pdf                   | nan                                                     | nan                                                                                                                                                                                                                                                    |
| 2025-03-16 | Gemma 3  Gemma 3 is a lightweight open model family (1B–27B parameters) that integrates vision understanding, multilingual coverage, and extended context windows (up to 128K tokens). Here is everything you need to know:   <br>● Multimodal architecture                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://storage.googleapis.com/deepmind-gemma/Gemma3Report.pdf                                                      | https://x.com/omarsar0/status/1899828483888762948       | nan                                                                                                                                                                                                                                                    |
| 2025-03-16 | Monitoring Reasoning Models for Misbehavior  Researchers from OpenAI examine how LLMs that use chain-of-thought (CoT) reasoning can be monitored for misaligned behaviors, including reward hacking. Key points include:   <br>● CoT monitoring catches hidden exploits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | https://cdn.openai.com/abs/34f2ada6-870f-4c26-9790-fd8def56387f/CoT_Monitoring.pdf                                  | https://x.com/OpenAI/status/1899143752918409338         | nan                                                                                                                                                                                                                                                    |
| 2025-03-16 | Gemini Robotics  Google DeepMind unveils Gemini Robotics, a family of embodied AI models designed to bring large multimodal reasoning capabilities into robotics. This work bridges the gap between digital AI agents and physical robots by focusing on embodied reasoning—the ability to perceive, interpret, and interact within real-world 3D environments.   <br>● Vision-Language-Action architecture                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://storage.googleapis.com/deepmind-gemini-robotics/gemini_robotics_report.pdf                                  | https://x.com/GoogleDeepMind/status/1899839624068907335 | nan                                                                                                                                                                                                                                                    |
| 2025-03-16 | Auditing LLMs for Hidden Objectives  Anthropic proposes a new framework for systematically auditing LLMs to uncover hidden goals or objectives that go beyond what users and developers explicitly intend. The researchers deliberately train a language model with a concealed objective (making it exploit reward model flaws in RLHF) and then attempt to expose it with different auditing techniques.   <br>● Hidden reward hacking                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | https://assets.anthropic.com/m/317564659027fb33/original/Auditing-Language-Models-for-Hidden-Objectives.pdf         | https://x.com/AnthropicAI/status/1900217234825634236    | nan                                                                                                                                                                                                                                                    |
| 2025-03-09 | Conversational Speech Model  Researchers from Sesame propose an end-to-end multimodal TTS approach for natural, context-aware speech in real-time conversational AI systems.  <br>● Beyond one-to-many TTS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | nan                                                                                                                 | nan                                                     | {"Technical Report": "https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice"}                                                                                                                                                           |
| 2025-03-09 | Differentiable Logic Cellular Automata  A team from Google's Paradigms of Intelligence introduces a fully discrete twist on Neural Cellular Automata (NCA) by replacing floating-point neural layers with Differentiable Logic Gate Networks. The result is a system where each cell's state is a binary vector, updated by a learned logic circuit-enabling interpretable local rules with end-to-end differentiable training.  <br>● Local logic gates instead of continuous neurons                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | https://google-research.github.io/self-organising-systems/difflogic-ca/?hn                                          | https://x.com/omarsar0/status/1898040198283640929       | nan                                                                                                                                                                                                                                                    |
| 2025-03-02 | Claude 3.7 Sonnet  Anthropic releases a system card for its latest hybrid reasoning model, Claude 3.7 Sonnet, detailing safety measures, evaluations, and a new "extended thinking" mode. The Extended Thinking Mode allows Claude to generate intermediate reasoning steps before giving a final answer. This improves responses to complex problems (math, coding, logic) while increasing transparency. Key results include:   <br>● Visible Thought Process                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | nan                                                                                                                 | https://x.com/AnthropicAI/status/1894092430560965029    | {"System Card": "https://assets.anthropic.com/m/785e231869ea8b3b/original/claude-3-7-sonnet-system-card.pdf"}                                                                                                                                          |
| 2025-03-02 | GPT-4.5  OpenAI introduces GPT-4.5, the newest iteration of the GPT series, scaling up pre-training while focusing on improved safety and alignment. Key insights include:   <br>● General-purpose model with broader knowledge                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | nan                                                                                                                 | https://x.com/omarsar0/status/1895204032177676696       | {"System Card": "https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf"}                                                                                                                                                                              |
| 2025-02-23 | MoBA  MoBA is a new attention mechanism that enhances efficiency in handling long-context sequences for LLMs while maintaining strong performance.  Key insights:   <br> ● Adaptive Attention for Long Contexts                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | https://github.com/MoonshotAI/MoBA/blob/master/MoBA_Tech_Report.pdf                                                 | https://x.com/Kimi_Moonshot/status/1891825059599352259  | nan                                                                                                                                                                                                                                                    |
| 2025-02-23 | Open-Reasoner-Zero  Open-Reasoner-Zero (ORZ) is an open-source large-scale minimalist reinforcement learning (RL) framework that enhances reasoning capabilities. ORZ demonstrates significant scalability requiring only 1/30th of the training steps of DeepSeek-R1-Zero-Qwen-32B to outperform it on GPQA Diamond. Key contributions and findings:   <br> ● Minimalist RL Training Works                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero/blob/main/ORZ_paper.pdf                                    | https://x.com/CyouSakura/status/1892428094075502960     | nan                                                                                                                                                                                                                                                    |
| 2025-02-23 | The AI CUDA Engineer  Sakana AI introduces The AI CUDA Engineer, an end-to-end agentic system that can produce highly optimized CUDA kernels.  Key contributions:   <br> ● Why is this research important?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | nan                                                                                                                 | https://x.com/SakanaAILabs/status/1892385766510338559   | {"Technical Report": "https://pub.sakana.ai/static/paper.pdf", "Blog": "https://sakana.ai/ai-cuda-engineer/", "Dataset": "https://pub.sakana.ai/ai-cuda-engineer"}                                                                                     |
| 2025-02-23 | AI Co-Scientist  Google introduces AI co-scientist, a multi-agent AI system built with Gemini 2.0 to help accelerate scientific breakthroughs.  Key highlights:   <br> ● What's the goal of this AI co-scientist?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf                                                 | https://x.com/omarsar0/status/1892223515660579219       | nan                                                                                                                                                                                                                                                    |
| 2025-02-16 | Brain-to-Text Decoding: A Non-Invasive Approach via Typing  Meta AI’s Brain2Qwerty model translates brain activity into text by decoding signals from non-invasive recordings (EEG/MEG) while users type. Key results include:   <br> ● Non-invasive BCI breakthrough: Brain2Qwerty leverages EEG and MEG  brainwaves (recorded as participants type memorized sentences) to  predict text, eliminating the need for surgical implants.   <br> ● Deep learning pipeline: The system uses a convolutional module to  extract signal features, a transformer to model temporal patterns, and  a character-level language model to refine outputs.   <br> ● Rapid progress in accuracy: MEG-based decoding achieved a 32%  character error rate (vs. 67% with EEG), and the top participant  reached 19% CER, showing dramatic improvement over prior non-invasive  methods.   <br> ● Towards practical communication aids: Demonstrates the potential for  restoring communication in paralyzed patients using external brain  monitors. Challenges remain in achieving real-time letter-by-letter  decoding and making MEG technology more portable.                                                                                                                                                                                                                                                                                                                                  | https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/                | https://x.com/JeanRemiKing/status/1887899974454698058   | nan                                                                                                                                                                                                                                                    |
| 2025-02-02 | o3-mini  OpenAI has launched o3-mini, their newest cost-efficient reasoning model, available in ChatGPT and API. The model excels in STEM-related tasks, particularly in science, math, and coding, while maintaining the low cost and reduced latency of its predecessor o1-mini. It introduces key developer features like function calling, Structured Outputs, and developer messages, making it  production-ready from launch.  o3-mini includes different reasoning effort levels (low, medium, and high) and improves performance across a wide range of tasks. It delivered responses 24% faster than o1-mini and achieved notable results in competition math, PhD-level science questions, and software engineering tasks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | nan                                                                                                                 | https://x.com/OpenAI/status/1885406586136383634         | {"System Card": "https://cdn.openai.com/o3-mini-system-card.pdf", "Blog": "https://openai.com/index/openai-o3-mini/"}                                                                                                                                  |
| 2025-02-02 | Qwen2.5-1M  Qwen releases two open-source LLMs, Qwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M, that can handle context lengths of up to 1 million tokens.  The models are built on a progressive training approach, starting with 4K tokens and gradually increasing to 256K tokens, then using length extrapolation techniques to reach 1M tokens. They've also released an inference framework based on vLLM that processes long inputs 3-7x faster through sparse attention methods.  The models show strong performance on both long-context and short-text tasks. The 14B model outperforms GPT-4o-mini across multiple long-context datasets while maintaining similar performance on shorter tasks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-1M/Qwen2_5_1M_Technical_Report.pdf                          | https://x.com/omarsar0/status/1883905564004241789       | {"Models": "https://huggingface.co/Qwen", "Qwen Chat App": "https://chat.qwenlm.ai/"}                                                                                                                                                                  |
| 2025-02-02 | Janus-Pro  An enhanced version of the previous Janus model for multimodal understanding and generation. The model incorporates three key improvements: optimized training strategies with longer initial training and focused fine-tuning, expanded training data including 90 million new samples for understanding and 72 million synthetic aesthetic samples for generation, and scaling to larger model sizes up to 7B parameters.  Janus-Pro achieves significant improvements in both multimodal understanding and text-to-image generation capabilities. The model outperforms existing solutions on various benchmarks, scoring 79.2 on MMBench for understanding tasks and achieving 80% accuracy on GenEval for text-to-image generation. The improvements also enhance image generation stability and quality, particularly for short prompts and fine details, though the current 384x384 resolution remains a limitation for certain tasks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf                                            | https://x.com/giffmana/status/1884011657191637126       | {"Models": "https://huggingface.co/deepseek-ai/Janus-Pro-7B"}                                                                                                                                                                                          |
| 2025-01-26 | DeepSeek-R1  DeepSeek introduces DeepSeek-R1, an advancement in reasoning capabilities achieved through reinforcement learning (RL). It involves two key models: DeepSeek-R1-Zero, which uses pure RL without supervised fine-tuning, and DeepSeek-R1, which combines RL with cold-start data. DeepSeek-R1-Zero demonstrates that models can develop sophisticated reasoning abilities through RL alone, achieving a 71.0% pass rate on AIME 2024 and matching OpenAI-o1-0912's performance. During training, it naturally evolved complex behaviors like self-verification and reflection. However, it faced challenges with readability and language mixing.  To address these limitations, DeepSeek-R1 uses a multi-stage approach: initial fine-tuning with high-quality chain-of-thought examples, reasoning-focused RL training, collecting new training data through rejection sampling, and final RL optimization across all scenarios. This resulted in performance comparable to OpenAI-o1-1217, with 79.8% accuracy on AIME 2024 and 97.3% on MATH-500, while maintaining output readability and consistency.  DeepSeek also successfully distilled DeepSeek-R1's capabilities into smaller models, with their 7B model outperforming larger competitors and their 32B model achieving results close to  OpenAI-o1-mini. This demonstrates the effectiveness of distilling reasoning patterns from larger models rather than training smaller models directly through RL. | https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf                                                | https://x.com/deepseek_ai/status/1881318130334814301    | {"Code": "https://huggingface.co/deepseek-ai", "App": "https://chat.deepseek.com/"}                                                                                                                                                                    |
| 2025-01-26 | Humanity’s Last Exam  Humanity's Last Exam is a new multi-modal benchmark designed to test the limits of LLMs. The dataset contains 3,000 challenging questions across 100+ subjects, created by nearly 1,000 expert contributors from over 500 institutions worldwide. Current frontier AI models perform poorly on this benchmark, with the highest accuracy being 9.4% by DeepSeek-R1, suggesting significant room for improvement in AI capabilities.  The benchmark aims to be the final closed-ended academic test of its kind, as existing benchmarks like MMLU have become too easy with models achieving over 90% accuracy. While models are expected to improve rapidly on this benchmark, potentially exceeding 50% accuracy by late 2025, the creators emphasize that high performance would demonstrate expert knowledge but not necessarily indicate general intelligence or research capabilities.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | https://static.scale.com/uploads/654197dc94d34f66c0f5184e/Publication%20Ready%20Humanity%27s%20Last%20Exam.pdf      | https://x.com/DanHendrycks/status/1882433928407241155   | {"Dataset": "https://huggingface.co/datasets/cais/hle"}                                                                                                                                                                                                |
| 2025-01-26 | Scaling RL with LLMs  Kimi introduces k1.5, a multimodal LLMtrained using RL that achieves state-of-the-art performance across reasoning tasks. The model leverages long context scaling up to 128k tokens and improved policy optimization methods, establishing a simplified yet effective RL framework without complex techniques like Monte Carlo tree search or value functions. Notably, k1.5 matches OpenAI's o1 performance on various benchmarks including 77.5 on AIME and 96.2 on MATH 500.  The model also introduces effective long2short methods that use long-chain-of-thought techniques to improve shorter models, achieving superior results in constrained settings. Using these techniques, k1.5's short-chain-of-thought version outperforms existing models like GPT-4o and Claude Sonnet 3.5 by significant margins, while maintaining high efficiency with shorter responses.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf                                                     | https://x.com/omarsar0/status/1881749719212552280       | {"GitHub": "https://github.com/MoonshotAI/Kimi-k1.5"}                                                                                                                                                                                                  |
| 2025-01-26 | Chain-of-Agents  A new framework for handling long-context tasks using multiple LLM agents working together. CoA splits text into chunks and assigns worker agents to process each part sequentially, passing information between them before a manager agent generates the final output. This approach avoids the limitations of traditional methods like input reduction or window extension. Testing across multiple datasets shows CoA outperforms existing approaches by up to 10% on tasks like question answering and summarization. The framework works particularly well with longer inputs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | https://openreview.net/pdf?id=LuCLf4BJsr                                                                            | https://x.com/omarsar0/status/1882824941101629829       | nan                                                                                                                                                                                                                                                    |
| 2025-01-26 | Trading Test-Time Compute for Adversarial Robustness  Shows preliminary evidence that giving reasoning models like o1-preview and o1-mini more time to "think" during inference can improve their defense against adversarial attacks. Experiments covered various tasks, from basic math problems to image classification, showing that increasing  inference-time compute often reduces the success rate of attacks to near zero. The approach doesn't work uniformly across all scenarios, particularly with certain StrongREJECT benchmark tests, and controlling how models use their compute time remains challenging. Despite these constraints, the findings suggest a promising direction for improving AI security without relying on traditional adversarial training methods.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | https://cdn.openai.com/papers/trading-inference-time-compute-for-adversarial-robustness-20250121_1.pdf              | https://x.com/OpenAI/status/1882129444212740482         | nan                                                                                                                                                                                                                                                    |
| 2025-01-12 | Cosmos World Foundation Model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | https://research.nvidia.com/publication/2025-01_cosmos-world-foundation-model-platform-physical-ai                  | https://x.com/EthanHe_42/status/1876487556755521798     | nan                                                                                                                                                                                                                                                    |
| 2025-01-12 | Process Reinforcement through Implicit Rewards                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | https://curvy-check-498.notion.site/Process-Reinforcement-through-Implicit-Rewards-15f4fcb9c42180f1b498cc9b2eaf896f | https://x.com/lifan__yuan/status/1874867809983033649    | nan                                                                                                                                                                                                                                                    |
| 2025-01-05 | Machine-Assisted Proof                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | https://www.ams.org//notices/202501/rnoti-p6.pdf                                                                    | https://x.com/omarsar0/status/1873045937259462656       | nan                                                                                                                                                                                                                                                    |
| 2025-01-05 | Measuring Higher Level Mathematical Reasoning                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | https://openreview.net/forum?id=YXnwlZe0yf&noteId=yrsGpHd0Sf                                                        | https://x.com/omarsar0/status/1874489752243597635       | nan                                                                                                                                                                                                                                                    |